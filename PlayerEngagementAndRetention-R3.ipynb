{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "a5779dba-b0a2-4fca-80de-5b2d486dbcfb",
      "cell_type": "markdown",
      "source": "# Player Engagement & Retention Analysis\n\n\n### Introduction\n\nThis notebook documents the cleaning and exploratory analysis of a simulated dataset for a fictional live-service video game. Dashboards and final data visualization for this project can be found at (LINK HERE).\n\n##### Industry: Video Games/Live-Service Games\n##### Company Type: Major Publisher\n##### Primary Audience: Product Managers/Game Designers (responsible for content scope, cadence, and post-launch tuning)\n\n##### Core Analytical Question\n* How do player engagement and retention metrics change before and after a major content update, and which player segments are most affected?\n##### Additional Stakeholder Questions\n* Which features or content introduced in the update are most associated with increases or decreases in engagement among different player segments?\n* Are there identifiable patterns of player behavior post-update that predict long-term retention or churn for high-value segments?\n\n\n### Objective\n\nThe objective of this analysis is to enable stakeholders (e.g., product managers, live-ops teams, and game designers) to evaluate the impact of a major content update on player engagement and retention and to identify which player segments are positively or negatively affected.\n\nBy comparing pre- and post-update engagement scores and D1/D7/D30 retention outcomes across player segments, this analysis should allow stakeholders to:\n* Assess whether the content update successfully increased short-term and long-term player retention\n* Identify segments at risk of disengagement or churn following the update\n* Understand how engagement behaviors (frequency, session depth, and social interaction) relate to post-update retention\n* Inform future content, live-ops timing, and targeted interventions aimed at improving player retention and sustained engagement\n\nUltimately, this analysis is intended to support data-informed decisions about content design, update cadence, and post-update player targeting in a live-service game environment.\n\n\n### Definitions\n\n##### Engagement\nFor the sake of this analysis, a player can be considered engaged based on three criteria: session frequency (played at least 1 day per week or 4 days per month), session duration (played for at least 30 minutes per session), and social interaction (participated in at least one multiplayer event per session). I developed the following formulae to determine an \"engagement score\" for each player:\n\n1. Frequency score $F=\\frac{Days\\:played\\:in\\:period}{Target\\:days}$\n\n2. Duration score $D=\\frac{Average\\:session\\:duration}{Target\\:duration}$\n\n3. Social score $S=\\frac{Average\\:social\\:interactions\\:per\\:session}{Target\\:number}$\n\n4. Engagement score $E=F \\times D \\times S$\n\nFrequency, duration, and social scores are weighted equally for the purpose of this analysis. An engagement score $\\ge$ 1 will indicate a player that demonstrates meaningful engagement across all three behavioral dimensions (and can therefore be considered engaged).\n\n##### Retention\nFor the sake of this analysis, a player is considered retained if they return to the game and demonstrate continued activity after the reference point (in this case, a major content update). Retention is defined using industry-standard benchmarks with window-based criteria:\n\nD1 Retention: Player logged in and completed at least one gameplay session 1 day after the content update\n\nD7 Retention: Player logged in and completed at least one gameplay session within 7 days of the content update\n\nD30 Retention: Player logged in and completed at least one gameplay session within 30 days of the content update\n\nA “gameplay session” is defined as a session meeting the minimum activity threshold (≥ 30 minutes of playtime), ensuring retention reflects meaningful return behavior rather than a trivial login. These retention metrics are cumulative window-based measures and are used to assess short-, mid-, and long-term player return behavior following the update.\n\n\n### Assumptions and Limitations\n\nThis analysis uses a simulated dataset designed to approximate realistic player behavior in a live-service game. Results are illustrative and demonstrate analytical approach rather than real-world performance.\n\nEngagement is measured using a composite score based on session frequency, duration, and social interaction. These metrics act as behavioral proxies and do not capture qualitative factors such as player sentiment or satisfaction.\n\nFrequency, duration, and social interaction are weighted equally in the engagement score. This assumes comparable impact across dimensions, which may vary by genre or player segment and would require validation in a production environment.\n\nRetention is defined as returning to the game and completing at least one session of ≥ 30 minutes. This prioritizes meaningful engagement but may exclude shorter, intentional player interactions.\n\nPre- vs. post-update comparisons assume the content update is the primary driver of observed changes. External influences (e.g., marketing efforts, seasonality, competing releases) are not explicitly controlled for, so findings should be interpreted as associative rather than causal.",
      "metadata": {}
    },
    {
      "id": "dc1f890b-2cc3-4834-b094-c9ebb6372a96",
      "cell_type": "markdown",
      "source": "### Data Loading and Audit\n\nThe code block below imports the dataset and displays the first five records to confirm the dataset loaded correctly.",
      "metadata": {}
    },
    {
      "id": "103eb1f3-f9c0-4a39-a1f9-ae8ee100fb70",
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\ndf = pd.read_csv('player_engagement_data.csv')\nprint(df.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "  session_id  player_id    game_title        date  session_duration_min  \\\n0  S00000001  P00010000  Mythic Quest  2024-04-26                 101.0   \n1  S00000002  P00010000  Mythic Quest  2024-05-01                 145.0   \n2  S00000003  P00010000  Mythic Quest  2024-05-25                   NaN   \n3  S00000004  P00010000  Mythic Quest  2024-05-27                  27.0   \n4  S00000005  P00010000  Mythic Quest  2024-06-03                 134.0   \n\n   in_game_purchases_usd level platform region player_type  \\\n0                    NaN     9     Xbox    NaN         NaN   \n1                    0.0    10     Xbox    NaN         NaN   \n2                    0.0    13     Xbox    NaN         NaN   \n3                    0.0    15     Xbox    NaN         NaN   \n4                    NaN    15     Xbox    NaN         NaN   \n\n  account_age_category  achievement_count  social_interactions churn_flag  \n0                  new               19.0                 31.0          0  \n1                  new               18.0                 36.0          0  \n2                  new               27.0                 45.0          0  \n3                  new               -1.0                  4.0          0  \n4                  new               36.0                 20.0          0  \n"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "66c66acb-89a4-4ab7-9768-3ab19c75e27b",
      "cell_type": "markdown",
      "source": "\nNext, I print the datatypes of the dataset so I can get a feel for the information contained in the dataset and see whether the columns are typed correctly.",
      "metadata": {}
    },
    {
      "id": "0e5dea3d-f02d-46d7-a547-9ddcb65d40a1",
      "cell_type": "code",
      "source": "print(\"\\n--- Datatypes ---\")\nprint(df.dtypes)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- Datatypes ---\nsession_id                object\nplayer_id                 object\ngame_title                object\ndate                      object\nsession_duration_min     float64\nin_game_purchases_usd    float64\nlevel                     object\nplatform                  object\nregion                    object\nplayer_type               object\naccount_age_category      object\nachievement_count        float64\nsocial_interactions      float64\nchurn_flag                object\ndtype: object\n"
        }
      ],
      "execution_count": 2
    },
    {
      "id": "aad54076-366c-4219-9ae6-ad777845bd52",
      "cell_type": "markdown",
      "source": "Right away, I can see that the 'level' column is mistyped. Although player level is stored numerically, it represents an ordinal progression rather than a continuous quantitative measure. So I convert the 'level' column to an object datatype.",
      "metadata": {}
    },
    {
      "id": "7475bd3a-3b7a-4d6a-a71d-274fa61f9e16",
      "cell_type": "code",
      "source": "df['level'] = df['level'].astype(object)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "id": "cde087fb-5c90-473f-9540-341946bc121b",
      "cell_type": "markdown",
      "source": "I also suspect that the 'churn_flag' column should be a boolean. I check the unique values in the 'churn_flag' column, convert the \"No\"s to 0 and the \"Yes\"s to 1, and convert the column's datatype to bool.",
      "metadata": {}
    },
    {
      "id": "93ad84ec-b1dc-4908-904c-862d9cc16ee0",
      "cell_type": "code",
      "source": "df['churn_flag'] = (\n    df['churn_flag']\n      .replace({'Yes': 1, 'No': 0})\n      .pipe(pd.to_numeric, errors='coerce')\n      .astype('boolean')\n)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "f891cca5-7b12-4774-958c-1ebe889d73f2",
      "cell_type": "markdown",
      "source": "The last datatype I want to update is for the 'date' column. I convert it to a datetime type.",
      "metadata": {}
    },
    {
      "id": "935904a7-9643-4c13-a5fc-f50fdfc15bd5",
      "cell_type": "code",
      "source": "df['date'] = pd.to_datetime(df['date'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "5f5e70ce-f7a0-4ca9-a290-12d8adcf6a36",
      "cell_type": "markdown",
      "source": "I check my work and make sure that all datatypes are now correct.",
      "metadata": {}
    },
    {
      "id": "073ee63b-e199-4f84-b2fd-27122b4df2ca",
      "cell_type": "code",
      "source": "print(\"\\n--- Datatypes R1 ---\")\nprint(df.dtypes)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- Datatypes R1 ---\nsession_id                       object\nplayer_id                        object\ngame_title                       object\ndate                     datetime64[ns]\nsession_duration_min            float64\nin_game_purchases_usd           float64\nlevel                            object\nplatform                         object\nregion                           object\nplayer_type                      object\naccount_age_category             object\nachievement_count               float64\nsocial_interactions             float64\nchurn_flag                      boolean\ndtype: object\n"
        }
      ],
      "execution_count": 6
    },
    {
      "id": "cea9558f-1d27-4e57-b2dc-5e0d655c3997",
      "cell_type": "markdown",
      "source": "Now that my data is typed correctly, I print a summary of the dataset so I can look for anomalies.",
      "metadata": {}
    },
    {
      "id": "0e078d62-2f47-4d76-8666-8f85d8b6644f",
      "cell_type": "code",
      "source": "print(\"\\n--- Statistical Summary (All Columns) ---\")\nprint(df.describe(include='all'))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- Statistical Summary (All Columns) ---\n       session_id  player_id    game_title                           date  \\\ncount       45049      45049         45049                          45049   \nunique      45049       9653             1                            NaN   \ntop     S00000001  P00019999  Mythic Quest                            NaN   \nfreq            1          8         45049                            NaN   \nmean          NaN        NaN           NaN  2024-06-12 16:55:39.723412224   \nmin           NaN        NaN           NaN            2024-04-16 00:00:00   \n25%           NaN        NaN           NaN            2024-05-13 00:00:00   \n50%           NaN        NaN           NaN            2024-06-12 00:00:00   \n75%           NaN        NaN           NaN            2024-07-13 00:00:00   \nmax           NaN        NaN           NaN            2024-08-14 00:00:00   \nstd           NaN        NaN           NaN                            NaN   \n\n        session_duration_min  in_game_purchases_usd  level platform region  \\\ncount           42818.000000           29169.000000  44511    32191  27906   \nunique                   NaN                    NaN     71        5      5   \ntop                      NaN                    NaN    MAX       pc   ASIA   \nfreq                     NaN                    NaN   1274     6686   5835   \nmean              111.439628              11.583020    NaN      NaN    NaN   \nmin                 8.000000               0.000000    NaN      NaN    NaN   \n25%                60.000000               0.000000    NaN      NaN    NaN   \n50%               108.000000               0.000000    NaN      NaN    NaN   \n75%               158.000000              11.420000    NaN      NaN    NaN   \nmax               283.000000             290.250000    NaN      NaN    NaN   \nstd                61.608191              31.898434    NaN      NaN    NaN   \n\n       player_type account_age_category  achievement_count  \\\ncount        38296                37249       43640.000000   \nunique           6                    5                NaN   \ntop           free              Veteran                NaN   \nfreq          6637                 7789                NaN   \nmean           NaN                  NaN          28.361320   \nmin            NaN                  NaN          -1.000000   \n25%            NaN                  NaN          15.000000   \n50%            NaN                  NaN          27.000000   \n75%            NaN                  NaN          40.000000   \nmax            NaN                  NaN          96.000000   \nstd            NaN                  NaN          18.035244   \n\n        social_interactions churn_flag  \ncount          41847.000000      45049  \nunique                  NaN          2  \ntop                     NaN      False  \nfreq                    NaN      43366  \nmean              27.365689        NaN  \nmin                0.000000        NaN  \n25%               13.000000        NaN  \n50%               27.000000        NaN  \n75%               40.000000        NaN  \nmax               74.000000        NaN  \nstd               16.918065        NaN  \n"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "65ec4dca-18cd-4648-a0ab-2ce33bd2e4f6",
      "cell_type": "markdown",
      "source": "Before moving on to the data cleaning phase, I note the unusual minimum value for the 'achievement_count' column so I can investigate.",
      "metadata": {}
    },
    {
      "id": "4ce24b61-a1a4-4e5d-9857-3a9c98e9eb6a",
      "cell_type": "markdown",
      "source": "### Data Cleaning and Preparation\n\nI start with column-by-column checks to make sure spelling, capitalization, and whitespace are all used consistently. I also check column-specific parameters, as shown below. The following code block checks that every value in 'session_id' is formatted correctly and there are no missing sessions.",
      "metadata": {}
    },
    {
      "id": "1fb2dbf6-dfae-47cf-94fa-54df9d117634",
      "cell_type": "code",
      "source": "import re\nfrom typing import Dict, Any\n\ndef validate_id_format(df: pd.DataFrame, col: str, prefix: str = None, digits: int = 8) -> Dict[str, Any]:\n    \"\"\"\n    Validate ID format for a column.\n    - Expected format: '<PREFIX>' followed by exactly `digits` digits (default 8), e.g. 'S00000001' or 'P00000001'.\n    - If `prefix` is None, infer from the first non-null value's first character (uppercased).\n    Returns a dict with:\n      - 'prefix': inferred/used prefix (single char)\n      - 'pattern': the regex used\n      - 'valid_mask': boolean Series (True where format matched)\n      - 'digits_str': Series of captured digit strings (NaN where not matched)\n      - 'digits_int': Series of ints for valid rows (index aligned, dtype Int64 for nullable ints)\n      - 'invalid_rows': DataFrame of rows that did not match (includes original NaNs)\n    \"\"\"\n    if col not in df.columns:\n        raise KeyError(f\"Column '{col}' not in dataframe\")\n\n    orig = df[col]\n    sample = orig.dropna().astype(str).str.strip()\n    if sample.empty:\n        # nothing to validate\n        return {\n            'prefix': None,\n            'pattern': None,\n            'valid_mask': pd.Series([False] * len(df), index=df.index),\n            'digits_str': pd.Series([pd.NA] * len(df), index=df.index, dtype=\"object\"),\n            'digits_int': pd.Series([pd.NA] * len(df), index=df.index, dtype=\"Int64\"),\n            'invalid_rows': df.copy()\n        }\n\n    used_prefix = (prefix.upper() if prefix is not None else sample.iloc[0][0].upper())\n    pattern = rf'^{re.escape(used_prefix)}(\\d{{{digits}}})$'\n\n    s = orig.astype(str).str.strip()\n    original_na_mask = orig.isna()\n\n    digits_str = s.str.extract(pattern)[0]    # captured digits or NaN\n    valid_mask = (~digits_str.isna()) & (~original_na_mask)\n\n    # ints for valid rows, use pandas nullable Int64 so missingness is preserved if needed\n    digits_int = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n    if valid_mask.any():\n        digits_int.loc[valid_mask] = digits_str[valid_mask].astype(int)\n\n    invalid_rows = df[~valid_mask].copy()\n\n    return {\n        'prefix': used_prefix,\n        'pattern': pattern,\n        'valid_mask': valid_mask,\n        'digits_str': digits_str,\n        'digits_int': digits_int,\n        'invalid_rows': invalid_rows\n    }\n\n\ndef assess_sequence(digits_int: pd.Series, df: pd.DataFrame = None, prefix: str = \"S\", digits: int = 8) -> Dict[str, Any]:\n    \"\"\"\n    Given a Series of integer ids (aligned to the original dataframe index) for VALID rows,\n    check duplicates and missingness in the contiguous range min..max.\n\n    Parameters:\n      - digits_int: pd.Series of ints (nullable Int64) containing only valid numeric ids or pd.NA for invalid rows.\n      - df: optional original DataFrame. If provided, duplicate_rows will be returned as rows from this df.\n      - prefix: prefix to use when formatting missing ids (single char)\n      - digits: number of digits for zero-padding when formatting missing ids\n\n    Returns dict with:\n      - 'duplicate_rows': DataFrame (if df provided) containing rows involved in duplicates; else list of duplicated numeric values\n      - 'duplicate_values': list of numeric values that are duplicated (empty if none)\n      - 'missing_ids': list of formatted missing ids (e.g. 'S00000005')\n      - 'summary': dict with counts and min/max\n    \"\"\"\n    # Filter to present numeric values\n    present = digits_int.dropna().astype(int)\n    if present.empty:\n        summary = {\n            'valid_count': 0,\n            'duplicate_count': 0,\n            'min_numeric_id': None,\n            'max_numeric_id': None,\n            'missing_count': None\n        }\n        return {\n            'duplicate_rows': (df.iloc[0:0].copy() if df is not None else []),\n            'duplicate_values': [],\n            'missing_ids': [],\n            'summary': summary\n        }\n\n    # Find duplicate numeric values\n    dup_mask = present.duplicated(keep=False)\n    duplicate_values = sorted(present[dup_mask].unique().tolist())\n\n    if df is not None:\n        # select rows in original df corresponding to duplicated numeric ids\n        duplicate_rows = df.loc[present.index[dup_mask]].copy()\n    else:\n        duplicate_rows = duplicate_values  # fallback: list of duplicated numeric ids\n\n    # Check missing numbers in the contiguous range min..max\n    mn = int(present.min())\n    mx = int(present.max())\n    full_set = set(range(mn, mx + 1))\n    present_set = set(present.tolist())\n    missing_nums = sorted(full_set - present_set)\n    missing_ids = [f\"{prefix}{n:0{digits}d}\" for n in missing_nums]\n\n    summary = {\n        'valid_count': int(present.size),\n        'duplicate_count': int(duplicate_rows.shape[0]) if isinstance(duplicate_rows, pd.DataFrame) else len(duplicate_values),\n        'min_numeric_id': mn,\n        'max_numeric_id': mx,\n        'missing_count': len(missing_ids)\n    }\n\n    return {\n        'duplicate_rows': duplicate_rows,\n        'duplicate_values': duplicate_values,\n        'missing_ids': missing_ids,\n        'summary': summary\n    }\n\nvalidate_id_format(df, 'session_id')\n\nfmt_res = validate_id_format(df, 'session_id')\nprint(\"Pattern used:\", fmt_res['pattern'])\nprint(\"Invalid rows (first 10):\")\ndisplay(fmt_res['invalid_rows'].head(10))\nseq_res = assess_sequence(fmt_res['digits_int'], df=df, prefix=fmt_res['prefix'])\nprint(\"Sequence summary:\", seq_res['summary'])\nprint(\"First 20 missing ids:\", seq_res['missing_ids'][:20])\ndisplay(seq_res['duplicate_rows'].head(10))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Pattern used: ^S(\\d{8})$\nInvalid rows (first 10):\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Empty DataFrame\nColumns: [session_id, player_id, game_title, date, session_duration_min, in_game_purchases_usd, level, platform, region, player_type, account_age_category, achievement_count, social_interactions, churn_flag]\nIndex: []",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session_id</th>\n      <th>player_id</th>\n      <th>game_title</th>\n      <th>date</th>\n      <th>session_duration_min</th>\n      <th>in_game_purchases_usd</th>\n      <th>level</th>\n      <th>platform</th>\n      <th>region</th>\n      <th>player_type</th>\n      <th>account_age_category</th>\n      <th>achievement_count</th>\n      <th>social_interactions</th>\n      <th>churn_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Sequence summary: {'valid_count': 45049, 'duplicate_count': 0, 'min_numeric_id': 1, 'max_numeric_id': 45049, 'missing_count': 0}\nFirst 20 missing ids: []\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Empty DataFrame\nColumns: [session_id, player_id, game_title, date, session_duration_min, in_game_purchases_usd, level, platform, region, player_type, account_age_category, achievement_count, social_interactions, churn_flag]\nIndex: []",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session_id</th>\n      <th>player_id</th>\n      <th>game_title</th>\n      <th>date</th>\n      <th>session_duration_min</th>\n      <th>in_game_purchases_usd</th>\n      <th>level</th>\n      <th>platform</th>\n      <th>region</th>\n      <th>player_type</th>\n      <th>account_age_category</th>\n      <th>achievement_count</th>\n      <th>social_interactions</th>\n      <th>churn_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "id": "c079f8c1-0924-4d98-8d6b-ac85b6c4196f",
      "cell_type": "markdown",
      "source": "'session_id' appears to be formatted correctly, and I can see from my summary above that there are no duplicate session IDs in this dataset, so I move on to the next column. For 'player_id', I just want to make sure that every ID is formatted correctly.",
      "metadata": {}
    },
    {
      "id": "5aac093d-3022-4caa-9f58-0cac4ca35b65",
      "cell_type": "code",
      "source": "validate_id_format(df, 'player_id')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'prefix': 'P',\n 'pattern': '^P(\\\\d{8})$',\n 'valid_mask': 0        True\n 1        True\n 2        True\n 3        True\n 4        True\n          ... \n 45044    True\n 45045    True\n 45046    True\n 45047    True\n 45048    True\n Length: 45049, dtype: bool,\n 'digits_str': 0        00010000\n 1        00010000\n 2        00010000\n 3        00010000\n 4        00010000\n            ...   \n 45044    00019999\n 45045    00019999\n 45046    00019999\n 45047    00019999\n 45048    00019999\n Name: 0, Length: 45049, dtype: object,\n 'digits_int': 0        10000\n 1        10000\n 2        10000\n 3        10000\n 4        10000\n          ...  \n 45044    19999\n 45045    19999\n 45046    19999\n 45047    19999\n 45048    19999\n Length: 45049, dtype: Int64,\n 'invalid_rows': Empty DataFrame\n Columns: [session_id, player_id, game_title, date, session_duration_min, in_game_purchases_usd, level, platform, region, player_type, account_age_category, achievement_count, social_interactions, churn_flag]\n Index: []}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20
    },
    {
      "id": "bdc5c556-fb76-4f1e-b220-bc21d1b88b57",
      "cell_type": "markdown",
      "source": "Next I check the 'date' column for any null (NaT) values.",
      "metadata": {}
    },
    {
      "id": "e4ad09f1-ac92-4015-bb30-038415178f10",
      "cell_type": "code",
      "source": "num_missing_date = df['date'].isna().sum()\nprint(f\"date NaT count: {num_missing_date}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "date NaT count: 0\n"
        }
      ],
      "execution_count": 21
    },
    {
      "id": "1eaa0047-6a2e-4e44-a4dc-87441bfe7a85",
      "cell_type": "markdown",
      "source": "Then I check 'session_duration_min' for missing values.",
      "metadata": {}
    },
    {
      "id": "f341ebd1-2c91-4567-9220-5d4cf901bbd1",
      "cell_type": "code",
      "source": "num_missing_duration = df['session_duration_min'].isna().sum()\nprint(f\"session duration NaN count: {num_missing_duration}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "session duration NaN count: 2231\n"
        }
      ],
      "execution_count": 23
    },
    {
      "id": "e3f5890c-b308-46e3-9e2d-a04411623641",
      "cell_type": "markdown",
      "source": "There are 2,231 missing values in 'session_duration_min'. Further research is required to determine why these values are missing. I start with a quick sanity check.",
      "metadata": {}
    },
    {
      "id": "69719968-1a8c-4b6b-be2b-b5d72a9dc5bf",
      "cell_type": "code",
      "source": "# basic counts + percent\nn_total = len(df)\nn_missing = df['session_duration_min'].isna().sum()\nprint(n_missing, \"missing of\", n_total, f\"({n_missing/n_total:.1%})\")\n\n# peek at some missing rows\ndf[df['session_duration_min'].isna()].sample(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "2231 missing of 45049 (5.0%)\n"
        },
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      session_id  player_id    game_title       date  session_duration_min  \\\n28656  S00028657  P00016336  Mythic Quest 2024-06-07                   NaN   \n9947   S00009948  P00012209  Mythic Quest 2024-04-18                   NaN   \n13679  S00013680  P00013041  Mythic Quest 2024-07-22                   NaN   \n25760  S00025761  P00015700  Mythic Quest 2024-06-02                   NaN   \n9341   S00009342  P00012087  Mythic Quest 2024-06-01                   NaN   \n21851  S00021852  P00014827  Mythic Quest 2024-04-19                   NaN   \n22489  S00022490  P00014983  Mythic Quest 2024-06-26                   NaN   \n13274  S00013275  P00012962  Mythic Quest 2024-05-21                   NaN   \n44129  S00044130  P00019795  Mythic Quest 2024-07-31                   NaN   \n13808  S00013809  P00013070  Mythic Quest 2024-06-23                   NaN   \n\n       in_game_purchases_usd level     platform region player_type  \\\n28656                  13.55    31  PlayStation   ASIA         NaN   \n9947                     NaN    21  PLAYSTATION    NaN      Casual   \n13679                    NaN    24          NaN   ASIA     Premium   \n25760                   0.00     6           pc    OCE     Premium   \n9341                    0.00    54          NaN    NaN        free   \n21851                    NaN    30  PlayStation     SA        free   \n22489                 100.97    36           pc    NaN       Whale   \n13274                   0.00    14  PLAYSTATION    NaN        Free   \n44129                    NaN    36         Xbox     EU       Whale   \n13808                   0.00    48           pc   ASIA     Premium   \n\n      account_age_category  achievement_count  social_interactions  churn_flag  \n28656                  New               36.0                 13.0       False  \n9947                   new               20.0                 31.0       False  \n13679                  New               43.0                  NaN       False  \n25760                  new               16.0                  6.0       False  \n9341               veteran               26.0                 31.0       False  \n21851              Veteran                2.0                 28.0       False  \n22489              Veteran               25.0                 11.0       False  \n13274                  New               26.0                 11.0       False  \n44129                  NaN               34.0                 56.0       False  \n13808                  New               49.0                  6.0       False  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session_id</th>\n      <th>player_id</th>\n      <th>game_title</th>\n      <th>date</th>\n      <th>session_duration_min</th>\n      <th>in_game_purchases_usd</th>\n      <th>level</th>\n      <th>platform</th>\n      <th>region</th>\n      <th>player_type</th>\n      <th>account_age_category</th>\n      <th>achievement_count</th>\n      <th>social_interactions</th>\n      <th>churn_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28656</th>\n      <td>S00028657</td>\n      <td>P00016336</td>\n      <td>Mythic Quest</td>\n      <td>2024-06-07</td>\n      <td>NaN</td>\n      <td>13.55</td>\n      <td>31</td>\n      <td>PlayStation</td>\n      <td>ASIA</td>\n      <td>NaN</td>\n      <td>New</td>\n      <td>36.0</td>\n      <td>13.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9947</th>\n      <td>S00009948</td>\n      <td>P00012209</td>\n      <td>Mythic Quest</td>\n      <td>2024-04-18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21</td>\n      <td>PLAYSTATION</td>\n      <td>NaN</td>\n      <td>Casual</td>\n      <td>new</td>\n      <td>20.0</td>\n      <td>31.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13679</th>\n      <td>S00013680</td>\n      <td>P00013041</td>\n      <td>Mythic Quest</td>\n      <td>2024-07-22</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>ASIA</td>\n      <td>Premium</td>\n      <td>New</td>\n      <td>43.0</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>25760</th>\n      <td>S00025761</td>\n      <td>P00015700</td>\n      <td>Mythic Quest</td>\n      <td>2024-06-02</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>6</td>\n      <td>pc</td>\n      <td>OCE</td>\n      <td>Premium</td>\n      <td>new</td>\n      <td>16.0</td>\n      <td>6.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9341</th>\n      <td>S00009342</td>\n      <td>P00012087</td>\n      <td>Mythic Quest</td>\n      <td>2024-06-01</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>54</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>free</td>\n      <td>veteran</td>\n      <td>26.0</td>\n      <td>31.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>21851</th>\n      <td>S00021852</td>\n      <td>P00014827</td>\n      <td>Mythic Quest</td>\n      <td>2024-04-19</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>30</td>\n      <td>PlayStation</td>\n      <td>SA</td>\n      <td>free</td>\n      <td>Veteran</td>\n      <td>2.0</td>\n      <td>28.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>22489</th>\n      <td>S00022490</td>\n      <td>P00014983</td>\n      <td>Mythic Quest</td>\n      <td>2024-06-26</td>\n      <td>NaN</td>\n      <td>100.97</td>\n      <td>36</td>\n      <td>pc</td>\n      <td>NaN</td>\n      <td>Whale</td>\n      <td>Veteran</td>\n      <td>25.0</td>\n      <td>11.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13274</th>\n      <td>S00013275</td>\n      <td>P00012962</td>\n      <td>Mythic Quest</td>\n      <td>2024-05-21</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>14</td>\n      <td>PLAYSTATION</td>\n      <td>NaN</td>\n      <td>Free</td>\n      <td>New</td>\n      <td>26.0</td>\n      <td>11.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>44129</th>\n      <td>S00044130</td>\n      <td>P00019795</td>\n      <td>Mythic Quest</td>\n      <td>2024-07-31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>36</td>\n      <td>Xbox</td>\n      <td>EU</td>\n      <td>Whale</td>\n      <td>NaN</td>\n      <td>34.0</td>\n      <td>56.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13808</th>\n      <td>S00013809</td>\n      <td>P00013070</td>\n      <td>Mythic Quest</td>\n      <td>2024-06-23</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>48</td>\n      <td>pc</td>\n      <td>ASIA</td>\n      <td>Premium</td>\n      <td>New</td>\n      <td>49.0</td>\n      <td>6.0</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24
    },
    {
      "id": "e0cd7d05-6ac7-4d1e-850e-dd31317a679f",
      "cell_type": "markdown",
      "source": "The preview does not make the reason for missingness immediately clear, so I check to see if other related columns are missing for the same records.",
      "metadata": {}
    },
    {
      "id": "a6322fe6-51f1-4212-9583-efa39afe765c",
      "cell_type": "code",
      "source": "cols = ['date', 'platform','region', 'player_type', 'account_age_category', 'social_interactions']\ndf_missing = df[df['session_duration_min'].isna()]\ndf_missing[cols].info()\ndf_missing[cols].head(20)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nIndex: 2231 entries, 2 to 45038\nData columns (total 6 columns):\n #   Column                Non-Null Count  Dtype         \n---  ------                --------------  -----         \n 0   date                  2231 non-null   datetime64[ns]\n 1   platform              1582 non-null   object        \n 2   region                1409 non-null   object        \n 3   player_type           1892 non-null   object        \n 4   account_age_category  1847 non-null   object        \n 5   social_interactions   2090 non-null   float64       \ndtypes: datetime64[ns](1), float64(1), object(4)\nmemory usage: 87.1+ KB\n"
        },
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "          date     platform region player_type account_age_category  \\\n2   2024-05-25         Xbox    NaN         NaN                  new   \n46  2024-04-24          NaN    NaN         NaN                  NaN   \n52  2024-05-20  PlayStation     na       Whale                  new   \n90  2024-08-14  PLAYSTATION     na        Free                  New   \n112 2024-07-08          NaN   ASIA     Premium         Intermediate   \n113 2024-04-20  PlayStation     SA     PREMIUM                  NaN   \n119 2024-08-04  PlayStation     SA     PREMIUM                  NaN   \n145 2024-05-06           pc   ASIA        Free                  New   \n151 2024-08-01  PlayStation     na        Free              Veteran   \n155 2024-07-16         Xbox     na        Free                  NaN   \n158 2024-07-16           pc    NaN         NaN                  new   \n175 2024-05-28  PlayStation   ASIA     Premium              Veteran   \n193 2024-05-13         Xbox    NaN        free              veteran   \n234 2024-05-18           PC    NaN      Casual                  new   \n240 2024-07-03           pc   ASIA         NaN                  new   \n261 2024-06-28           pc    NaN         NaN                  NaN   \n300 2024-05-29           pc     EU        Free                  new   \n317 2024-06-19  PLAYSTATION    OCE     Premium              veteran   \n361 2024-04-29           PC    NaN        free              veteran   \n425 2024-05-15  PLAYSTATION     na     PREMIUM                  new   \n\n     social_interactions  \n2                   45.0  \n46                  25.0  \n52                   NaN  \n90                  56.0  \n112                 54.0  \n113                 14.0  \n119                 47.0  \n145                  2.0  \n151                 13.0  \n155                  5.0  \n158                  1.0  \n175                 13.0  \n193                 27.0  \n234                  5.0  \n240                 12.0  \n261                 23.0  \n300                 43.0  \n317                  NaN  \n361                 28.0  \n425                 31.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>platform</th>\n      <th>region</th>\n      <th>player_type</th>\n      <th>account_age_category</th>\n      <th>social_interactions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>2024-05-25</td>\n      <td>Xbox</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>new</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2024-04-24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>2024-05-20</td>\n      <td>PlayStation</td>\n      <td>na</td>\n      <td>Whale</td>\n      <td>new</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>2024-08-14</td>\n      <td>PLAYSTATION</td>\n      <td>na</td>\n      <td>Free</td>\n      <td>New</td>\n      <td>56.0</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>2024-07-08</td>\n      <td>NaN</td>\n      <td>ASIA</td>\n      <td>Premium</td>\n      <td>Intermediate</td>\n      <td>54.0</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>2024-04-20</td>\n      <td>PlayStation</td>\n      <td>SA</td>\n      <td>PREMIUM</td>\n      <td>NaN</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>2024-08-04</td>\n      <td>PlayStation</td>\n      <td>SA</td>\n      <td>PREMIUM</td>\n      <td>NaN</td>\n      <td>47.0</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>2024-05-06</td>\n      <td>pc</td>\n      <td>ASIA</td>\n      <td>Free</td>\n      <td>New</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>2024-08-01</td>\n      <td>PlayStation</td>\n      <td>na</td>\n      <td>Free</td>\n      <td>Veteran</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>2024-07-16</td>\n      <td>Xbox</td>\n      <td>na</td>\n      <td>Free</td>\n      <td>NaN</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>2024-07-16</td>\n      <td>pc</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>new</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>2024-05-28</td>\n      <td>PlayStation</td>\n      <td>ASIA</td>\n      <td>Premium</td>\n      <td>Veteran</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>2024-05-13</td>\n      <td>Xbox</td>\n      <td>NaN</td>\n      <td>free</td>\n      <td>veteran</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>234</th>\n      <td>2024-05-18</td>\n      <td>PC</td>\n      <td>NaN</td>\n      <td>Casual</td>\n      <td>new</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>240</th>\n      <td>2024-07-03</td>\n      <td>pc</td>\n      <td>ASIA</td>\n      <td>NaN</td>\n      <td>new</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>2024-06-28</td>\n      <td>pc</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>2024-05-29</td>\n      <td>pc</td>\n      <td>EU</td>\n      <td>Free</td>\n      <td>new</td>\n      <td>43.0</td>\n    </tr>\n    <tr>\n      <th>317</th>\n      <td>2024-06-19</td>\n      <td>PLAYSTATION</td>\n      <td>OCE</td>\n      <td>Premium</td>\n      <td>veteran</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>2024-04-29</td>\n      <td>PC</td>\n      <td>NaN</td>\n      <td>free</td>\n      <td>veteran</td>\n      <td>28.0</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>2024-05-15</td>\n      <td>PLAYSTATION</td>\n      <td>na</td>\n      <td>PREMIUM</td>\n      <td>new</td>\n      <td>31.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31
    },
    {
      "id": "9ee753d9-b376-433f-a0a1-86c754dab758",
      "cell_type": "markdown",
      "source": "Almost half of the records with a missing session duration also have a missing region, but more research would be required to determine if the two are correlated. For now, I move on and compare distributions and frequencies for rows with versus without missing session durations.",
      "metadata": {}
    },
    {
      "id": "be1129a7-888e-44e6-8c2b-fa9887daa104",
      "cell_type": "code",
      "source": "# categorical columns to inspect\nfor c in cols:\n    print(\"==\", c, \"==\")\n    print(\"missing rows:\")\n    print(df_missing[c].value_counts(dropna=False).head(10))\n    print(\"overall:\")\n    print(df[c].value_counts(dropna=False).head(10))\n    print()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "== date ==\nmissing rows:\ndate\n2024-04-29    31\n2024-06-28    29\n2024-04-26    28\n2024-06-21    28\n2024-06-10    28\n2024-08-08    26\n2024-07-06    26\n2024-04-17    25\n2024-07-02    25\n2024-05-06    25\nName: count, dtype: int64\noverall:\ndate\n2024-05-03    451\n2024-04-23    436\n2024-06-06    435\n2024-04-18    431\n2024-05-02    420\n2024-05-10    420\n2024-04-25    418\n2024-04-19    417\n2024-05-04    415\n2024-05-14    415\nName: count, dtype: int64\n\n== platform ==\nmissing rows:\nplatform\nNaN            649\npc             334\nPC             325\nPLAYSTATION    318\nPlayStation    312\nXbox           293\nName: count, dtype: int64\noverall:\nplatform\nNaN            12858\npc              6686\nPLAYSTATION     6468\nPlayStation     6442\nPC              6305\nXbox            6290\nName: count, dtype: int64\n\n== region ==\nmissing rows:\nregion\nNaN     822\nSA      301\nASIA    300\nEU      273\nOCE     273\nna      262\nName: count, dtype: int64\noverall:\nregion\nNaN     17143\nASIA     5835\nOCE      5671\nSA       5528\nEU       5467\nna       5405\nName: count, dtype: int64\n\n== player_type ==\nmissing rows:\nplayer_type\nWhale      340\nNaN        339\nPremium    337\nCasual     323\nfree       317\nFree       292\nPREMIUM    283\nName: count, dtype: int64\noverall:\nplayer_type\nNaN        6753\nfree       6637\nCasual     6503\nPremium    6413\nWhale      6294\nFree       6279\nPREMIUM    6170\nName: count, dtype: int64\n\n== account_age_category ==\nmissing rows:\naccount_age_category\nVeteran         408\nIntermediate    389\nNaN             384\nnew             376\nNew             339\nveteran         335\nName: count, dtype: int64\noverall:\naccount_age_category\nNaN             7800\nVeteran         7789\nnew             7657\nIntermediate    7490\nveteran         7292\nNew             7021\nName: count, dtype: int64\n\n== social_interactions ==\nmissing rows:\nsocial_interactions\nNaN     141\n28.0     53\n6.0      51\n23.0     47\n17.0     46\n42.0     46\n30.0     45\n9.0      44\n24.0     42\n43.0     42\nName: count, dtype: int64\noverall:\nsocial_interactions\nNaN     3202\n17.0     832\n22.0     824\n19.0     819\n16.0     816\n37.0     799\n20.0     796\n21.0     793\n6.0      792\n38.0     791\nName: count, dtype: int64\n\n"
        }
      ],
      "execution_count": 33
    },
    {
      "id": "9f14aee0-8520-4fde-a287-613c03b60051",
      "cell_type": "markdown",
      "source": "I can see that missing durations are spread across many dates rather than concentrated on a single outage day. That suggests missingness is not caused by a single-day instrumentation failure.",
      "metadata": {}
    },
    {
      "id": "3b7da1f2-8611-4250-b495-531cf06518de",
      "cell_type": "markdown",
      "source": " Many of the records missing session durations are also missing other values (e.g. platform NaN = 649 among the missing-rows subset). This indicates that rows with missing duration often also lack other metadata, which could indicate upstream log loss or incomplete events. In a real-world scenario, I would flag this to the appropriate team or investigate outside the dataset as needed.",
      "metadata": {}
    },
    {
      "id": "0ce8be6f-6904-4bbc-8c95-161c18735f21",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}